# MDD_deliverable_project

## **Introduction**

This report is covering data mining practices and Machine Learning algorithms (further ML). Before diving deeper, let us clearify the terminology. At first is data mining, it is a process of discovering patterns, trends, and insigths from large data sets through different techniques such as ML and statystical analysis. Steps such as collecting, cleaning and analyzing is involved as well, and all this information is required to decision-making or prediction of the future actions or events. Therefore, ML is a subset of Artificial Intelegence that involves algorithms and statystical models that enable machines to learn and predict and decide without complicated programming. The main part of ML is training data, and the performance improves over time with experience. This report is covering ML models, such as kNN, Logistic Regression, Naive Bayes, RFC (Random Forest classifier), SVM (Support Vector Machine), Neural Network. Those will be described and explained in the following paragraph.

## **Models covered in this repository**

kNN is supervised machine learning algorithm for classification and regression tasks. It identifies the k nearest data points in a training data set to a new input and assigns to the most common to the neighbors. 

RFC is an ensemble learning method that constructs a multitude of decision trees during training and combines their predictions to make more accurate and robust classifications or regressions. It is known for its ability to handle complex datasets and reduce the risk of overfitting.

Logistic Regression is a statistical model used for binary classification tasks, which predicts the probability that an input belongs to one of two classes based on a linear relationship between the input features and a log-odds function, known as the logistic function.

Naive Bayes is a probabilistic machine learning algorithm used primarily for classification tasks. It's based on Bayes' theorem and assumes that input features are independent of each other (hence "naive"), making it computationally efficient. Naive Bayes calculates the probability of an input belonging to a particular class and selects the class with the highest probability as the prediction.

SVM is a powerful supervised machine learning algorithm used for classification and regression tasks. SVM finds a hyperplane that best separate data points into different classes while maximizing the margin between the classes

Neural Network is a machine learning model inspired by the structure and function of the human brain. It consists of interconnected artificial neurons (nodes) organized into layers (input, hidden, and output), with each connection having a weight. It is used in a a wide range of tasks, including image recognition, natural language processing, and reinforcement learning.


## **Summary**

All in all, the most important piece is the data set. Picking and finding good set is one of the crucial parts in data mining. By working with current dataset we have faced challanges that we didn't expect. First challange, was how does everything works, realizing definitions, tuning and learning to read and analyze an outcome. Data set we found relatively quickly, and we all agreed on the data set. Next step was coding and learning the models. After all, when most of the job was done, we realized that our models are predicting 'no' answers in the data set. However, this is useful for banking campaign, this way banks can identify the group to whom it is not relevant, in this way distincting the target group easier. However, digging deeper is required to be able to switch around the models, so we can realize to whom we are marketing the campaign. All the steps that were taken in the model you can see by the code, it describes main idea of the function or action, why and how it is relevant. From cleaining, splitting, preprocessing, splitting to tuning. 

    Karolis Liubavicius
